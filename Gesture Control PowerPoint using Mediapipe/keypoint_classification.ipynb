{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,092</span> (4.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,092\u001b[0m (4.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,092</span> (4.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,092\u001b[0m (4.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m73/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7620 - loss: 0.5087  \n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7755 - loss: 0.4852 - val_accuracy: 0.8685 - val_loss: 0.2847\n",
      "Epoch 2/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8559 - loss: 0.3181\n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3110 - val_accuracy: 0.8811 - val_loss: 0.2329\n",
      "Epoch 3/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.8664 - loss: 0.2706\n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.2647 - val_accuracy: 0.9149 - val_loss: 0.1762\n",
      "Epoch 4/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8871 - loss: 0.2349\n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2310 - val_accuracy: 0.9693 - val_loss: 0.1320\n",
      "Epoch 5/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.9144 - loss: 0.2006\n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2008 - val_accuracy: 0.9786 - val_loss: 0.1106\n",
      "Epoch 6/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9151 - loss: 0.1898\n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.1867 - val_accuracy: 0.9810 - val_loss: 0.0921\n",
      "Epoch 7/1000\n",
      "\u001b[1m57/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9227 - loss: 0.1758\n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.1769 - val_accuracy: 0.9755 - val_loss: 0.0864\n",
      "Epoch 8/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9211 - loss: 0.1757\n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.1749 - val_accuracy: 0.9845 - val_loss: 0.0769\n",
      "Epoch 9/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9242 - loss: 0.1678\n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.1668 - val_accuracy: 0.9876 - val_loss: 0.0701\n",
      "Epoch 10/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9308 - loss: 0.1611\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1601 - val_accuracy: 0.9874 - val_loss: 0.0722\n",
      "Epoch 11/1000\n",
      "\u001b[1m52/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9284 - loss: 0.1642\n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.1624 - val_accuracy: 0.9881 - val_loss: 0.0737\n",
      "Epoch 12/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9320 - loss: 0.1572\n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.1568 - val_accuracy: 0.9843 - val_loss: 0.0688\n",
      "Epoch 13/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9318 - loss: 0.1486\n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1490 - val_accuracy: 0.9862 - val_loss: 0.0606\n",
      "Epoch 14/1000\n",
      "\u001b[1m95/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1445\n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1444 - val_accuracy: 0.9903 - val_loss: 0.0691\n",
      "Epoch 15/1000\n",
      "\u001b[1m81/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1414\n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1417 - val_accuracy: 0.9888 - val_loss: 0.0660\n",
      "Epoch 16/1000\n",
      "\u001b[1m86/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1450\n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1442 - val_accuracy: 0.9907 - val_loss: 0.0594\n",
      "Epoch 17/1000\n",
      "\u001b[1m95/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1329\n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1329 - val_accuracy: 0.9807 - val_loss: 0.0615\n",
      "Epoch 18/1000\n",
      "\u001b[1m95/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1315\n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1318 - val_accuracy: 0.9903 - val_loss: 0.0651\n",
      "Epoch 19/1000\n",
      "\u001b[1m50/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.1356 \n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1352 - val_accuracy: 0.9893 - val_loss: 0.0626\n",
      "Epoch 20/1000\n",
      "\u001b[1m94/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1311\n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1313 - val_accuracy: 0.9876 - val_loss: 0.0673\n",
      "Epoch 21/1000\n",
      "\u001b[1m95/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1303\n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1303 - val_accuracy: 0.9926 - val_loss: 0.0592\n",
      "Epoch 22/1000\n",
      "\u001b[1m81/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.1318\n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1319 - val_accuracy: 0.9874 - val_loss: 0.0623\n",
      "Epoch 23/1000\n",
      "\u001b[1m81/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1267\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9492 - loss: 0.1260 - val_accuracy: 0.9910 - val_loss: 0.0609\n",
      "Epoch 24/1000\n",
      "\u001b[1m86/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1290\n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1288 - val_accuracy: 0.9919 - val_loss: 0.0624\n",
      "Epoch 25/1000\n",
      "\u001b[1m83/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1265\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1261 - val_accuracy: 0.9926 - val_loss: 0.0575\n",
      "Epoch 26/1000\n",
      "\u001b[1m87/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1232\n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1237 - val_accuracy: 0.9929 - val_loss: 0.0660\n",
      "Epoch 27/1000\n",
      "\u001b[1m85/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1232\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1228 - val_accuracy: 0.9924 - val_loss: 0.0659\n",
      "Epoch 28/1000\n",
      "\u001b[1m94/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1133\n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1134 - val_accuracy: 0.9936 - val_loss: 0.0625\n",
      "Epoch 29/1000\n",
      "\u001b[1m98/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1203\n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1202 - val_accuracy: 0.9941 - val_loss: 0.0563\n",
      "Epoch 30/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9493 - loss: 0.1195\n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1186 - val_accuracy: 0.9945 - val_loss: 0.0605\n",
      "Epoch 31/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9516 - loss: 0.1191\n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1170 - val_accuracy: 0.9931 - val_loss: 0.0579\n",
      "Epoch 32/1000\n",
      "\u001b[1m84/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9574 - loss: 0.1075\n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1069 - val_accuracy: 0.9933 - val_loss: 0.0563\n",
      "Epoch 33/1000\n",
      "\u001b[1m92/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1076\n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1075 - val_accuracy: 0.9931 - val_loss: 0.0560\n",
      "Epoch 34/1000\n",
      "\u001b[1m86/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1134\n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1127 - val_accuracy: 0.9933 - val_loss: 0.0586\n",
      "Epoch 35/1000\n",
      "\u001b[1m88/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1006\n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1009 - val_accuracy: 0.9922 - val_loss: 0.0640\n",
      "Epoch 36/1000\n",
      "\u001b[1m81/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.0939\n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.0955 - val_accuracy: 0.9917 - val_loss: 0.0586\n",
      "Epoch 37/1000\n",
      "\u001b[1m89/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1044\n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1041 - val_accuracy: 0.9926 - val_loss: 0.0537\n",
      "Epoch 38/1000\n",
      "\u001b[1m91/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.0959\n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.0959 - val_accuracy: 0.9938 - val_loss: 0.0517\n",
      "Epoch 39/1000\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.0960\n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.0960 - val_accuracy: 0.9936 - val_loss: 0.0554\n",
      "Epoch 40/1000\n",
      "\u001b[1m88/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.0972\n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.0971 - val_accuracy: 0.9903 - val_loss: 0.0613\n",
      "Epoch 41/1000\n",
      "\u001b[1m89/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.0941\n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.0943 - val_accuracy: 0.9886 - val_loss: 0.0585\n",
      "Epoch 42/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9631 - loss: 0.0934\n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0929 - val_accuracy: 0.9905 - val_loss: 0.0638\n",
      "Epoch 43/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9628 - loss: 0.0919\n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0924 - val_accuracy: 0.9845 - val_loss: 0.0678\n",
      "Epoch 44/1000\n",
      "\u001b[1m49/99\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1017 \n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.0994 - val_accuracy: 0.9872 - val_loss: 0.0601\n",
      "Epoch 45/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9658 - loss: 0.0859\n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.0875 - val_accuracy: 0.9907 - val_loss: 0.0549\n",
      "Epoch 46/1000\n",
      "\u001b[1m51/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.0934 \n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.0932 - val_accuracy: 0.9627 - val_loss: 0.0815\n",
      "Epoch 47/1000\n",
      "\u001b[1m81/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.0904\n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.0910 - val_accuracy: 0.9862 - val_loss: 0.0618\n",
      "Epoch 48/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9676 - loss: 0.0907\n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0913 - val_accuracy: 0.9786 - val_loss: 0.0647\n",
      "Epoch 49/1000\n",
      "\u001b[1m49/99\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.0907 \n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.0914 - val_accuracy: 0.9888 - val_loss: 0.0521\n",
      "Epoch 50/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9654 - loss: 0.0842\n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.0843 - val_accuracy: 0.9800 - val_loss: 0.0690\n",
      "Epoch 51/1000\n",
      "\u001b[1m93/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0867\n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.0866 - val_accuracy: 0.9822 - val_loss: 0.0602\n",
      "Epoch 52/1000\n",
      "\u001b[1m88/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9645 - loss: 0.0915\n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.0911 - val_accuracy: 0.9879 - val_loss: 0.0522\n",
      "Epoch 53/1000\n",
      "\u001b[1m94/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0827\n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0825 - val_accuracy: 0.9883 - val_loss: 0.0491\n",
      "Epoch 54/1000\n",
      "\u001b[1m87/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0742\n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0748 - val_accuracy: 0.9743 - val_loss: 0.0653\n",
      "Epoch 55/1000\n",
      "\u001b[1m51/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0763 \n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0782 - val_accuracy: 0.9874 - val_loss: 0.0598\n",
      "Epoch 56/1000\n",
      "\u001b[1m52/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9720 - loss: 0.0793\n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0803 - val_accuracy: 0.9653 - val_loss: 0.0725\n",
      "Epoch 57/1000\n",
      "\u001b[1m51/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0854 \n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.0840 - val_accuracy: 0.9555 - val_loss: 0.0846\n",
      "Epoch 58/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9698 - loss: 0.0818\n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0815 - val_accuracy: 0.9793 - val_loss: 0.0550\n",
      "Epoch 59/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9701 - loss: 0.0904\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0892 - val_accuracy: 0.9670 - val_loss: 0.0750\n",
      "Epoch 60/1000\n",
      "\u001b[1m79/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0756\n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0755 - val_accuracy: 0.9653 - val_loss: 0.0732\n",
      "Epoch 61/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9701 - loss: 0.0805\n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0812 - val_accuracy: 0.9489 - val_loss: 0.0994\n",
      "Epoch 62/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9681 - loss: 0.0865\n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0855 - val_accuracy: 0.9736 - val_loss: 0.0681\n",
      "Epoch 63/1000\n",
      "\u001b[1m56/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9701 - loss: 0.0770\n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0775 - val_accuracy: 0.9734 - val_loss: 0.0664\n",
      "Epoch 64/1000\n",
      "\u001b[1m52/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9677 - loss: 0.0851\n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0823 - val_accuracy: 0.9803 - val_loss: 0.0570\n",
      "Epoch 65/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9736 - loss: 0.0743\n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0769 - val_accuracy: 0.9522 - val_loss: 0.0948\n",
      "Epoch 66/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9751 - loss: 0.0715\n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0731 - val_accuracy: 0.9551 - val_loss: 0.0923\n",
      "Epoch 67/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9754 - loss: 0.0731\n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0766 - val_accuracy: 0.9646 - val_loss: 0.0731\n",
      "Epoch 68/1000\n",
      "\u001b[1m53/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9737 - loss: 0.0714\n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0727 - val_accuracy: 0.9774 - val_loss: 0.0605\n",
      "Epoch 69/1000\n",
      "\u001b[1m51/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9701 - loss: 0.0784 \n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0793 - val_accuracy: 0.9743 - val_loss: 0.0635\n",
      "Epoch 70/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9702 - loss: 0.0817\n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0827 - val_accuracy: 0.9729 - val_loss: 0.0671\n",
      "Epoch 71/1000\n",
      "\u001b[1m56/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9695 - loss: 0.0746\n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0743 - val_accuracy: 0.9603 - val_loss: 0.0797\n",
      "Epoch 72/1000\n",
      "\u001b[1m54/99\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9724 - loss: 0.0796\n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0775 - val_accuracy: 0.9677 - val_loss: 0.0649\n",
      "Epoch 73/1000\n",
      "\u001b[1m55/99\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9736 - loss: 0.0675\n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0706 - val_accuracy: 0.9648 - val_loss: 0.0742\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b33e4e87c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0715 \n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "[1.0000000e+00 3.6310196e-21]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      2713\n",
      "           1       0.91      1.00      0.95      1493\n",
      "\n",
      "    accuracy                           0.96      4206\n",
      "   macro avg       0.95      0.97      0.96      4206\n",
      "weighted avg       0.97      0.96      0.97      4206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\clyde\\AppData\\Local\\Temp\\tmphx5e8xd7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\clyde\\AppData\\Local\\Temp\\tmphx5e8xd7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\clyde\\AppData\\Local\\Temp\\tmphx5e8xd7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1869359385232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1869446508992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1869338567680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1869465660656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1869465653264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1869465661712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6468"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clyde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000e+00 3.631033e-21]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
